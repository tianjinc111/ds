{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz 3\n",
    "DS 3000\n",
    "Spring 2021\n",
    "\n",
    "After completing the quiz below, please follow the instructions below to submit:\n",
    "1. \"Kernel\" -> \"Restart & Run All\"\n",
    "1. save your quiz file to this latest version\n",
    "1. upload the `.ipynb` to gradescope **before** clicking submit\n",
    "1. ensure that you can see your jupyter notebook in the gradescope interface after clicking \"submit\"\n",
    "\n",
    "We specify the last note above as gradescope will allow you to \"submit\" without uploading a file.  It is your responsibility to ensure that you've actually submitted a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "1. Scrape the rating, name and year of [The top 250 TV shows (per imdb)](https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250).  \n",
    "1. Identify the highest rated show of every year observed.  (Any show with the same rating, to the tenths place, can be considered the highest rated show for a given year).  One solution for the most recent years highest rated shows are:\n",
    "\n",
    "|    | imdb rate |           name |   year |\n",
    "|---:|----------:|---------------:|-------:|\n",
    "| 62 |       8.7 |     It's a Sin | 2021.0 |\n",
    "| 15 |       9.1 | The Last Dance | 2020.0 |\n",
    "|  4 |       9.4 |      Chernobyl | 2019.0 |\n",
    "| 24 |       9.0 |        Persona | 2018.0 |\n",
    "|  5 |       9.3 | Blue Planet II | 2017.0 |\n",
    "\n",
    "**Hints:**\n",
    "- Documentation counts\n",
    "    - variable names\n",
    "    - code \"chunking\" \n",
    "    - comment lines which explain each chunk's function\n",
    "- If the tag you're looking to `.find_all()` doesn't have a specific enough class (or no class at all) you might try finding some other html item which exclusively contains tags of the type you're interested in.  Remember, you can `.find_all()` items in a particular tag as well as the whole soup object.\n",
    "- `.sort_values()` and `drop_duplicates()` could be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The funcition is to get the whole html of the whole page\n",
    "def get_url(link):\n",
    "    \"\"\"\n",
    "    parsing throught the link and using request to get the whole html as a string\n",
    "    \n",
    "    Args:\n",
    "    link(\"string\"): the link of the target web\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    html(string) the text of the requested html\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #request the html and convert it to text\n",
    "    response = requests.get(link).text\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up the html_str get artist, source, track info, and stroing then into a dataframe.\n",
    "def clean_data(html_str):\n",
    "    \n",
    "    \"\"\" \n",
    "    parsing through the html_str by getting from the get_url fucntion,\n",
    "    then return a dataframe of the target information\n",
    "    Args:\n",
    "        html_str (str): the string of the html information\n",
    "\n",
    "    Returns:\n",
    "        df(dataframe): the dataframe that contains the target info we want\n",
    "    \"\"\"\n",
    "    \n",
    "    # the beautiful style of the html info\n",
    "    soup = BeautifulSoup(html_str)\n",
    "    #create the dic frame \n",
    "    dic = {\"imbd rate\" : [], \"name\": [],'year':[]}\n",
    "    namelist = []\n",
    "    ratelist = []\n",
    "    \n",
    "    yearlist = []\n",
    "\n",
    "    # find out the target class\n",
    "    for info in soup.find_all(class_ = 'lister-list'):\n",
    "        for title in  info.find_all(class_ = 'titleColumn'):\n",
    "            # get the info and store them to each list\n",
    "            name = title.text.split(\"\\n\")[2]\n",
    "            year = title.text.split()[-1].replace('(','').replace(')', '')\n",
    "            \n",
    "            namelist.append(name)\n",
    "            yearlist.append(year)\n",
    "            \n",
    "            \n",
    "        # find the class for rating info\n",
    "        for rating in info.find_all(class_ = 'ratingColumn imdbRating'):\n",
    "            rate = rating.text.strip()\n",
    "            \n",
    "            ratelist.append(rate)\n",
    "            \n",
    "    #assign values to the dic\n",
    "    dic[\"imbd rate\"] = ratelist\n",
    "    dic[\"name\"] = namelist\n",
    "    dic[\"year\"] = yearlist\n",
    "        \n",
    "    #create the datafrme with the complete dic\n",
    "    df = pd.DataFrame(dic)\n",
    "        \n",
    "    \n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imbd rate</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8.7</td>\n",
       "      <td>It's a Sin</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.1</td>\n",
       "      <td>The Last Dance</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>Chernobyl</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Persona</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.3</td>\n",
       "      <td>Blue Planet II</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imbd rate                  name  year\n",
       "65       8.7            It's a Sin  2021\n",
       "15       9.1        The Last Dance  2020\n",
       "4        9.4             Chernobyl  2019\n",
       "24       9.0               Persona  2018\n",
       "5        9.3        Blue Planet II  2017"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start the script and scrap the information. \n",
    "\n",
    "html_str = get_url('https://www.imdb.com/chart/toptv/?ref_=nv_tvv_250')\n",
    "\n",
    "table = clean_data(html_str)\n",
    "\n",
    "# initialize the info of the web and sort it to find out the max for each year. \n",
    "\n",
    "table.drop_duplicates(subset=['year'], keep='first').sort_values(by = [\"year\"], ascending = False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
