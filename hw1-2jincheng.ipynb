{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 HW 1\n",
    "\n",
    "Due: Tues Feb 02 @ 11:59 PM EST\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to gradescope.\n",
    "\n",
    "The `ipynb` format stores outputs from the last time you ran the notebook.  (When you open a notebook it has the figures and outputs of the last time you ran it too).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh run \"Kernel > Restart & Run All\" just before uploading the `ipynb` file to gradescope.\n",
    "\n",
    "### Academic Integrity\n",
    "\n",
    "**Writing your homework is an individual effort.**  You may discuss general python problems with other students but under no circumstances should you observe another student's code which was written for this assignment, from this year or past years.  Pop into office hours or post a piazza note if you have a specific question about your work you'd like another pair of eyes to talk through.  (Remember, mark your piazza note private if it contains anything which may be considered a solution to the exercise).\n",
    "\n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment.  For example, a python trick I find particularly clever (and useful, sometimes):\n",
    "\n",
    "```python\n",
    "from collections import defaultdict\n",
    "\n",
    "def tree(): \n",
    "    # https://gist.github.com/hrldcpr/2012250\n",
    "    return defaultdict(tree)\n",
    "```\n",
    "\n",
    "You need not cite the official python documentation or the documentation of any python library which is imported in the template (e.g. matplotlib, numpy, scipy).\n",
    "\n",
    "**Documentation / style counts for credit**  Please see our course's python style guide, available on canvas, for further information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown\n",
    "\n",
    "## Part 1 (15 points: (2, 2, 3, 2, 2, 4) pts per item in list below):\n",
    "Use the markdown language below to create your own brief wikipedia-esque description of any subject of interest. \n",
    "\n",
    "Your mini-wiki page must include:\n",
    "- three headers: a title, subtitle and subsubtitle (the #, ##, ### syntax)\n",
    "- an embedded image from a web address (use an [image hosting site](https://makeawebsitehub.com/free-photo-hosting/) if you'd like to upload your own)\n",
    "- a table of size at least 3 rows x 3 columns (needn't be correct, but must make sense)\n",
    "- a list\n",
    "- a link to another website\n",
    "- a link to another jupyter cell\n",
    "\n",
    "Please be brief in your text.  Aim for roughly 3 sentences total of text.  We won't grade based on content, but keep it class appropriate.  If you make the grader smile, no extra credit will be awarded beyond the satisfaction of having made somebody's day better :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please add cells as needed to put your answer directly below each corresponding Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the introduction of stock\n",
    "## Stock derivatives\n",
    "### stock index\n",
    "\n",
    "## Images\n",
    "![alt text](https://www.cmegroup.com/education/images/articles/2018/stock-index-spread-opportunities-fig01.png)\n",
    "\n",
    "\n",
    "\n",
    "| name of stock |      |    |      |\n",
    "|---------------|------|----|------|\n",
    "| skyHighcorp   | 3243 | 76 | 21.2 |\n",
    "| lowDownInc    | 2735 | 18 | 41   |\n",
    "| ValueNowInc   | 1894 | 12 | 22   |\n",
    "\n",
    "\n",
    "\n",
    "## Lists\n",
    "here is a list of top stock:\n",
    "- Apple Inc\n",
    "- Tesla Inc\n",
    "- FaceBook Inc\n",
    "\n",
    "\n",
    "## Links\n",
    "You can link to a nasdaq website from  [this one](https://www.nasdaq.com/). \n",
    "\n",
    "\n",
    "You can link to [another cell](#another_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is another topic about the stock basic knowledge\n",
    "<a id='another_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prisoner's Dilemma\n",
    "This section asks you to implement a game of repeated [prisoner's dilemma](https://en.wikipedia.org/wiki/Prisoner%27s_dilemma).   \n",
    "\n",
    "Prisoner's dilemma is a cooperation game.  Two players simultaneously tell if they will cooperate or not in a given round.  Points are awarded based on both player's cooperation (or not) decisions:\n",
    "- If both players cooperate with each other, each receives 2 points\n",
    "- If both players do not cooperate with each other, each receives 1 point\n",
    "- If one player cooperates while the other does not, the cooperating player gets 0 points, the non-cooperator receives 3 points\n",
    "\n",
    "Repeated prisoner's dilemma has the two players continue to play rounds until one player reaches some threshold of points (this threshold is stored as `score_to_win` below).  \n",
    "\n",
    "What makes repeated prisoner's dilemma so fun is that the history of your opponents decisions allow you to make an informed decision about whether you should cooperate or not in the current round.  In this implementation, we'll allow each player to choose to cooperate or not in a new round based exclusively on their opponents choice in the last round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (10 points): Copycat strategy\n",
    "Implement the `get_coop_copycat()` function below which copies the opponents last strategy.  Be sure to write the docstring yourself (for a simple function like this one, documentation is a worth a large portion of the credit ... please use the style guide!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coop_copycat(opp_last_coop=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    opp_last_coop: is a boolean that whether the previous \n",
    "    player choose to cooperate or not. \n",
    "\n",
    "    returns:\n",
    "    opp_last_coop: return the previous one's choice as a boolean.\n",
    "    \"\"\"\n",
    "\n",
    "    return opp_last_coop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "assert get_coop_copycat(opp_last_coop=True) == True\n",
    "assert get_coop_copycat(opp_last_coop=False) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (13 points): Friendly strategy\n",
    "Implement the `get_coop_friendly()` function below which ignores the opponents last strategy and chooses to cooperate 90% of the time.  (Use [np.random.choice()](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) to select a random number).  Be sure to write the docstring yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coop_friendly():\n",
    "    \"\"\"\n",
    "    return:\n",
    "    a random number from 0, 1, where 0 represent that \n",
    "    status that the player chooose not to be friendly coop, while 1\n",
    "    represent a coop-friendly. \n",
    "    \"\"\"\n",
    "    return np.random.choice(2,1,p=[0.1,0.9])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (6 points): Testing Friendly Strategy\n",
    "One way to test if our `get_coop_friendly` function works is to ensure that if we run it many times the result is close to its expected value.  In other words, our friendly player should produce about 9k (i.e. 9000) cooperates given 10k rounds of playing.  We'll say the function works if it outputs between 8k and 10k cooperations.\n",
    "\n",
    "Write a loop which counts the number of cooperations `get_coop_friendly()` produces in 10k rounds.  Use `assert` to check that this number of cooperations is indeed in the range we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#this is the script to check while we run the game for 10000 times, what will the friendly strategy output\n",
    "# the reuslt should in the range of 8000 to 10000\n",
    "\n",
    "#record is used to record the total times while the function return 1, which is friendly_coop\n",
    "record = 0\n",
    "for i in range(10000):\n",
    "    record = record + get_coop_friendly()[0]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#test whether the record is in the range of 8000 to 10000\n",
    "assert record in range(8000, 10000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 (21 points): Scoring\n",
    "Complete the `score_pdil()` function below to assign scores based on the scoring list directly above.\n",
    "\n",
    "Use the docstring and test cases to inform your implementation.  If `verbose=True`, you should print one of the following messages:\n",
    "- both players cooperate\n",
    "- both players do not cooperate\n",
    "- one player cooperates, the other does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_pdil(p0_coop, p1_coop, verbose=False):\n",
    "    \"\"\" scores a single round of prisoner's dilemma\n",
    "    \n",
    "    Args:\n",
    "        p0_coop (bool): True if player 0 cooperates,\n",
    "            otherwise false\n",
    "        p1_coop (bool): True if player 1 cooperates,\n",
    "            otherwise false\n",
    "        verbose (bool): toggles output to command line\n",
    "            \n",
    "    Returns:\n",
    "        p0_points (int): \"points\" earned by p0 this round\n",
    "        p1_points (int): \"points\" earned by p1 this round\n",
    "    \"\"\"\n",
    "    # cast both inputs to boolean\n",
    "    p0_coop = bool(p0_coop)\n",
    "    p1_coop = bool(p1_coop)\n",
    "\n",
    "    # the three potential answers\n",
    "    answers = [\"both players cooperate\",\"both players do not cooperate\",\"one player cooperates, the other does not\"]\n",
    "\n",
    "    # initialize the points of each to zero\n",
    "    p0_points = 0\n",
    "    p1_points = 0\n",
    "\n",
    "    # if the two both cooperate, then both get 2 poists\n",
    "    if p0_coop == True and p1_coop == True:\n",
    "        p0_points = 2\n",
    "        p1_points = 2\n",
    "        if verbose == True:\n",
    "            return answers[0]\n",
    "\n",
    "    # if only one coperate, then the one coopearte get zero while the other one get 3 points\n",
    "    elif p0_coop == True and p1_coop == False:\n",
    "        p0_points = 0\n",
    "        p1_points = 3\n",
    "        if verbose == True:\n",
    "            return answers[2]\n",
    "        \n",
    "\n",
    "    # if only one coperate, then the one coopearte get zero while the other one get 3 points\n",
    "    elif p0_coop == False and p1_coop == True:\n",
    "        p0_points = 3\n",
    "        p1_points = 0\n",
    "        if verbose == True: \n",
    "            return answers[2]\n",
    "       \n",
    "    # if neither of them choose to cooperate, then each of them get 1 points.\n",
    "    elif p0_coop == False and p1_coop == False:\n",
    "        p0_points = 1\n",
    "        p1_points = 1\n",
    "        if verbose == True:\n",
    "            return answers[1]\n",
    "\n",
    "    return p0_points, p1_points\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cases\n",
    "assert score_pdil(p0_coop=True, p1_coop=True) == (2, 2)\n",
    "assert score_pdil(p0_coop=True, p1_coop=False) == (0, 3)\n",
    "assert score_pdil(p0_coop=False, p1_coop=True) == (3, 0)\n",
    "assert score_pdil(p0_coop=False, p1_coop=False) == (1, 1)\n",
    "\n",
    "# my own test here, which is to check while the verbose is true:\n",
    "assert score_pdil(p0_coop=True, p1_coop= True, verbose= True) == \"both players cooperate\"\n",
    "assert score_pdil(p0_coop=True, p1_coop= False, verbose= True) == \"one player cooperates, the other does not\"\n",
    "assert score_pdil(p0_coop=False, p1_coop= False, verbose= True) == \"both players do not cooperate\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 (15 points): Friendly vs Copycat in repeated Prisoner's Dilemma\n",
    "\n",
    "Complete the `repeated_pdil()` function below which simulates the outcome of a game of repeated prisoner's dilemma between a friendly and copycat player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_pdil(score_to_win, coop_friendly_init=True):\n",
    "    \"\"\" runs repeated prisoners dilemma friendly vs copycat\n",
    "    \n",
    "    game ends when one player reaches score_to_win.\n",
    "    \n",
    "    note that copycat strategy requires the opponents last choice to\n",
    "    produce a new cooperation decision.  In the first round we use\n",
    "    coop_friendly_init as the friendly players \"previous round\" to\n",
    "    determine coop_copycat, the copycat's current round cooperation\n",
    "    \n",
    "    Args:\n",
    "        score_to_win (int): min threshold to declare (at least)\n",
    "            one player a winner and end game\n",
    "        coop_friendly_init (bool): initial condition of friendly\n",
    "            players \"previous round\"\n",
    "            \n",
    "    Returns:\n",
    "        score_copycat (int): total copycat player points\n",
    "        score_friendly (int): total friendly player points\n",
    "        num_rounds (int): number of rounds played\n",
    "    \"\"\"\n",
    "    #the score of two players are initialized as zero\n",
    "    score_copycat = 0\n",
    "    score_friendly = 0\n",
    "    #they all initialized as True\n",
    "    copycatpayer = True\n",
    "    friendlypayer = True\n",
    "\n",
    "    # track down how many times the game plays\n",
    "    num_rounds = 0\n",
    "    \n",
    "\n",
    "    #in the while loop, while the scores are less than the threshold,\n",
    "    #keep playing the game\n",
    "    while score_copycat < score_to_win and score_friendly < score_to_win:\n",
    "        \n",
    "        \n",
    "        #the copycatplayer always follow the previous one\n",
    "        copycatpayer = get_coop_copycat(coop_friendly_init)\n",
    "\n",
    "        #as defined in the previous get_coop_friendly funciton \n",
    "        #0 represent the false, and 1 represent True\n",
    "        n = get_coop_friendly()[0]\n",
    "\n",
    "        if n == 1:\n",
    "            friendlypayer = True\n",
    "            coop_friendly_init = True\n",
    "        else:\n",
    "            friendlypayer = False\n",
    "            coop_friendly_init = False\n",
    "\n",
    "\n",
    "        # simulated the scores of each player\n",
    "        score_friendly =  score_friendly + score_pdil(friendlypayer,copycatpayer)[0]\n",
    "\n",
    "        score_copycat = score_copycat + score_pdil(friendlypayer,copycatpayer)[1]\n",
    "\n",
    "        num_rounds = num_rounds + 1\n",
    "\n",
    "        \n",
    "\n",
    "    return score_copycat, score_friendly, num_rounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1001, 526)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated_pdil(1000, coop_friendly_init=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 (12 points): Is one strategy better than another?\n",
    "To test this, lets run 1000 games of repeated prisoner's dilemman, using the `repeated_pdil()`.  For each game let `score_to_win=20`.  We'll keep track of the outcomes of each game by counting the number of games which have a particular pair of final score tuples `(score_copycat, score_friendly)` in a dictionary called `score_count_dict`.  For example:\n",
    "\n",
    "```python\n",
    "score_count_dict = {(20, 0): 999, \n",
    "                    (20, 1): 1}\n",
    "```\n",
    "\n",
    "indicates that, of the 1000 total games:\n",
    "- 999 ended with copycat having a score of 20 while friendly has a score of 0\n",
    "- 1 ended with copycat having a score of 20 while friendly has a score of 1\n",
    "\n",
    "Note that `score_count_dict` only includes entries for game totals which were observed, none of the values are `0`.\n",
    "\n",
    "For (+3) extra credit, use a [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict) object for `score_count_dict`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {(21, 21): 355,\n",
       "             (19, 22): 42,\n",
       "             (20, 20): 496,\n",
       "             (18, 21): 64,\n",
       "             (17, 20): 43})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the variables, the dictionary to store the data\n",
    "score_count_dict = defaultdict()\n",
    "score_to_win = 20\n",
    "\n",
    "\n",
    "# play the game for 1000 times\n",
    "for i in range(1000):\n",
    "\n",
    "    result  = repeated_pdil(20,coop_friendly_init=True)\n",
    "\n",
    "    final_score = (result[0], result[1])\n",
    "    \n",
    "    \n",
    "    # the initial status of the dic\n",
    "    if final_score not in score_count_dict:\n",
    "        score_count_dict[final_score] = 1\n",
    "    # adding up on the dic\n",
    "    else:\n",
    "        score_count_dict[final_score] += 1\n",
    "\n",
    "\n",
    "\n",
    "score_count_dict\n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 (8 points): Executive Summary\n",
    "- print the `score_count_dict` you constructed above\n",
    "- Synthesize the results of your experiment into 1 or 2 clear sentences.  In particular, explain the result to someone who only wants to know:\n",
    "```\n",
    "How often does copycat or friendly score more points than the other?  How often do they tie?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {(21, 21): 355, (19, 22): 42, (20, 20): 496, (18, 21): 64, (17, 20): 43})\n"
     ]
    }
   ],
   "source": [
    "print(score_count_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as the result of our experiment, we found out that in the turns of 1000 times,\n",
    "there are 496 + 355 = 851 times that copycat and friendly got the same \n",
    "score (tie) while for  149times, friendly got more points and  times ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
